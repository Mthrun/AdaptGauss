EM_LGL=function(Data,Means,Sdevs,alphas,MaxNumberofIterations){

  # EM- Algorithm to calculate optimal Mixture Model of a Gaus and two log Gaus (positiv and negativ) for given data in one Dimension
  # In particular, no adding or removing of Gaussian kernels.
  # NOTE: this is probably not numerical stable.
  #
  # DESCRIPTION
  # 
  # INPUT
  # Data(1:AnzCases)          the data points as column vactor
  # Means(1:3)                estimated Kernels = means(clustercenters),
  # Sdevs(1:3)                estimated Kernels = standard deviations
  # alphas(1:3)               relative number of points in Pdfs (prior probabilities): sum(alphas) ==1
  #                             the first number of the Vectors belongs to the negativ Log Gaus distribution, 
  #                             the second number of the Vectors belongs to the Gaus distribution,
  #                             the third number of the Vectors belongs to the positiv Log Gaus distribution. 
  # MaxNumberofIterations
  # OUTPUT
  # EMmean(1:3)                     means of LGL generated by EM algorithm
  # EMsdev(1:3)                     standard deviations of LGL generated by EM algorithm
  # EMalphas(1:3)                    prior probabilities of Pdfs
  #
  #
  
  #
  # Altuhor Florian Meyer 2008
  # in \dbt\EMforGauss\
  nantovalue <- function(z,value){
    
    out<-z
    out[is.na(out)]<-value
    
    return (out) 
    
  }
  
  prctile<-function(x,p){
    #   matlab:
    #   Y = prctile(X,p) returns percentiles of the values in X. 
    #   p is a scalar or a vector of percent values. When X is a 
    #   vector, Y is the same size as p and Y(i) contains the p(i)th 
    #   percentile. When X is a matrix, the ith row of Y contains the 
    #   p(i)th percentiles of each column of X. For N-dimensional arrays,
    #   prctile operates along the first nonsingleton dimension of X.  
    if(length(p)==1){  
      if(p>1){p=p/100}
      
    }
    
    if(is.matrix(x) && ncol(x)>1){
      cols<-ncol(x)
      quants<-matrix(0,nrow=length(p),ncol=cols)
      for(i in 1:cols){
        quants[,i]<-quantile(x[,i],probs=p,type=5,na.rm=TRUE)
      }
    }else{
      quants<-quantile(x,p,type=5,na.rm=TRUE)
    }
    return(quants)
  }
  meanrobust <- function(x, p=0.1){
    
    if(is.matrix(x)){
      mhat<-c()
      for(i in 1:dim(x)[2]){
        mhat[i]<-mean(x[,i],trim=p,na.rm=TRUE)
      }
    } else  mhat<-mean(x,trim=p,na.rm=TRUE) 
    
    return (mhat) 
    
  }
  nantozero <- function(z){
    
    out<-nantovalue(z,0)
    
    return (out) 
    
  }
  
  
  stdrobust <- function(x,lowInnerPercentile=25){
    
    if(is.vector(x) || (is.matrix(x) && dim(x)[1]==1)) dim(x)<-c(length(x),1)
    
    lowInnerPercentile<-max(1,min(lowInnerPercentile,49))
    hiInnerPercentile<- 100 - lowInnerPercentile
    faktor<-sum(abs(qnorm(t(c(lowInnerPercentile,hiInnerPercentile)/100),0,1)))
    std<-sd(x,na.rm=TRUE)
    p<-c(lowInnerPercentile,hiInnerPercentile)/100
    quartile<-prctile(x,p)  
    if (ncol(x)>1)
      iqr<-quartile[2,]-quartile[1,]
    else
      iqr<-quartile[2]-quartile[1]
    
    shat<-c()
    for(i in 1:ncol(x)){
      shat[i]<-min(std[i],iqr[i]/faktor,na.rm=TRUE)
    }
    dim(shat)<-c(1,ncol(x))
    colnames(shat)<-colnames(x)
    return (shat) 
    
  }
  
  
  
  # how many Clustercenters
  L <- length(Means); 
  Ls <- length(Sdevs); 
  La <- length(alphas);
  if (!((L == Ls )&& (L== La) && ( L == 3))){
    warning('EMgauss: Number of means, sdevs and alphas must be 3');
  }# if not(L == S)
  AnzCases <- length(Data);
  if (!(sum(alphas)-1 <0.001)){
    warning('EMgauss: sum(alphas) must be euqal to 1');
  }# if not(L == S)
  
  #w = alphas; # initialize w
  Na= matrix(0,AnzCases,L); 
  sig=seq(0,0,length.out=L)
  mu=seq(0,0,length.out=L)
  sig[1] = sqrt(log(Sdevs[1]*Sdevs[1]/(Means[1]*Means[1])+1))
  sig[2] = Sdevs[2]
  sig[3] = sqrt(log(Sdevs[3]*Sdevs[3]/(Means[3]*Means[3])+1)) 
  mu[1] = (log(-Means[1])-0.5*sig[1]*sig[1])
  mu[2] =  Means[2]
  mu[3] = (log( Means[3])-0.5*sig[3]*sig[3])
  
  
  
  
  EMalphas = alphas;
  DataForAllDistributions = (Data[1:length(Data)]*matrix(1,length(Data),L))
  
  # Nullen vor dem Log elemenieren
  DataNullen = which(Data==0);
  AnzahlNullen = length(DataNullen);
  DataForAllDistributions[DataNullen,1] = 1; 
  DataForAllDistributions[DataNullen,3] = 1 ; 
  
  DataForAllDistributions[1:AnzCases,1] = log(abs(DataForAllDistributions[1:AnzCases,1]))*(sign(DataForAllDistributions[1:AnzCases,2])-1)*(-0.5) #(sign(...)*(-0.5) L?scht alle positiven Zahlen 
  DataForAllDistributions[1:AnzCases,3] = log(abs(DataForAllDistributions[1:AnzCases,3]))*(sign(DataForAllDistributions[1:AnzCases,2])+1)* 0.5   #(sign(...)*0.5 L?scht alle negativen Zahlen 
  for (t in 1:MaxNumberofIterations){ # update EM Parameters
    #1.) compute actual alpha weighted probability for each point
    
    ##Hier nachgucken, welche Funktionen verwendet werden m?ssen
    Na[1:AnzCases,1] = dlnorm(-Data,mu[1],sig[1])* EMalphas[1]; 
    Na[1:AnzCases,2] = dnorm( Data,mu[2],sig[2])* EMalphas[2]; 
    Na[1:AnzCases,3] = dlnorm( Data,mu[3],sig[3])* EMalphas[3]

    #2.) compute total probability for each point
    TotalEMGauss = Na[1:AnzCases,1]+Na[1:AnzCases,2]+Na[1:AnzCases,3];
                       #     PlotMixtures(unique(Data),mu,sig,EMalphas); 
                       #     title(['Iteration: ' num2str(t) ' W1:' num2str(EMalphas(1)) ' W2:' num2str(EMalphas(2))]);drawnow;
                       #3.) compute point's weight as 1.) divided by 2.)
    w= Na / (TotalEMGauss*matrix(1,AnzCases,L));
    #4.) update alphastrich AND weights
    alphastrich=seq(0,0,length.out=L)
    for (i in 1:AnzCases){
      alphastrich[1:L] = alphastrich[1:L]+w[i,1:L]; # = alpha * AnzCases
    }
    alphastrich = nantozero(alphastrich)
    ZeroInd = which(alphastrich<0.01)
    alphastrich[ZeroInd]=0.009 
    EMalphas = alphastrich/AnzCases
    ZeroInd = which(EMalphas<0.01)
    EMalphas[ZeroInd]=0
    if (sum(EMalphas) <0.01){ # no right solution found: give up search & return robust values
      EMalphas = seq(0,0,length.out=L)
      mu=EMalphas
      sig=EMalphas
      EMalphas[1] =1
      mu[1] = meanrobust(Data)
      sig[1] = stdrobust(Data)
      break
    }
    #5.) update means
    mu=seq(0,0,length.out=L)
    for (i in 1:AnzCases){
      mu[1:L] = mu[1:L]+w[i,1:L]*DataForAllDistributions[i,1:L]
    }
    mu = mu/alphastrich
    #mu = sum(w .* DataForAllDistributions)'./alphastrich;
    # account for weight ==0
    mu[ZeroInd] =0
    #6. update std devs
    temp=seq(0,0,length.out=L)
    for (i in 1:AnzCases){
      temp=temp+w[i,1:L]*(DataForAllDistributions[i,1:L]-mu)^2
    }
    sig=sqrt(temp/alphastrich)
    sig[ZeroInd] =1  
  }# for t=1:MaxNumberofIterations # update EM Parameters
  
  EMmean = c(-exp(mu[1]+sig[1]*sig[1]*0.5),
              mu[2],
              exp(mu[3]+sig[3]*sig[3]*0.5)
             )
  
  EMsdev = c(sqrt(exp(2*mu[1]+sig[1]*sig[1])*(exp(sig[1]*sig[1])-1)),
              sig[2],
              sqrt(exp(2*mu[3]+sig[3]*sig[3])*(exp(sig[3]*sig[3])-1))
             )

output <- list(EMmean=EMmean,EMsdev=EMsdev,EMalphas=EMalphas)
return(output)
}